from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
from datetime import datetime
import requests
import json


def crawl(radius):
    """
    ì§€ì •í•œ ë°˜ê²½ ë‚´ì˜ ìŒì‹ì  ì •ë³´ë¥¼ í¬ë¡¤ë§í•˜ì—¬ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜

    Parameters:
        radius (int): í¬ë¡¤ë§í•  ë°˜ê²½

    Returns:
        str: ì €ì¥ëœ JSON íŒŒì¼ ê²½ë¡œ
    """

    # ì›ê²© í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •
    options = webdriver.ChromeOptions()
    options.add_argument('--headless') 
    options.add_argument('--ignore-ssl-errors=yes')
    options.add_argument('--ignore-certificate-errors')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--no-sandbox')
    options.add_argument('--log-level=3')
    options.add_argument('--incognito')
    options.add_argument('--disable-images')
    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36 Edg/115.0.1901.200'
    options.add_argument(f'user-agent={user_agent}')
    
    # í¬ë¡¬ ì›¹ ë“œë¼ì´ë²„ ì‹¤í–‰
    driver = webdriver.Chrome(options=options)
    
    # ë„¤ì´ë²„ ì§€ë„ URL ì„¤ì • (ë°˜ê²½ ë°˜ì˜)
    url = f"https://map.naver.com/p?c={radius},0,0,0,dh"
    driver.get(url)
    driver.maximize_window()
    
    # ê²€ìƒ‰ì°½ì— ìŒì‹ì  ê²€ìƒ‰
    search_box = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, "input.input_search"))
    )
    search_box.send_keys("ìŒì‹ì ")
    search_box.send_keys(Keys.RETURN)
    
    time.sleep(1)

    # ê²€ìƒ‰ ê²°ê³¼ iframeìœ¼ë¡œ ì „í™˜
    driver.switch_to.frame("searchIframe")
    # ì˜µì…˜ ë²„íŠ¼ì´ ë“±ì¥í•  ë•Œê¹Œì§€ ëŒ€ê¸°
    WebDriverWait(driver, 30).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, "._restaurant_filter_item:first-child > a"))
    )

    # ì˜µì…˜ ë²„íŠ¼ í´ë¦­
    option_btn = driver.find_element(By.CSS_SELECTOR, "._restaurant_filter_item:first-child > a")
    option_btn.send_keys(Keys.ENTER)

    # 'ì¸ê¸° ë§ì€ ìˆœ' ë²„íŠ¼ í´ë¦­
    most_btn = driver.find_element(By.CSS_SELECTOR, "#_popup_rank+div > span:first-child > a")
    most_btn.send_keys(Keys.ENTER)

    # 'ì˜ì—… ì¤‘' ë²„íŠ¼ í´ë¦­
    working_btn = driver.find_element(By.CSS_SELECTOR, "#_popup_property+div > span:first-child > a")
    working_btn.send_keys(Keys.ENTER)

    # ê²€ìƒ‰ ê²°ê³¼ ë²„íŠ¼ í´ë¦­
    result_btn = driver.find_element(By.CSS_SELECTOR, ".qeVvz a:last-child")
    result_btn.send_keys(Keys.ENTER)
    time.sleep(1)

    # ìŠ¤í¬ë¡¤ ì „ì— ë§ˆì§€ë§‰ ìš”ì†Œ ìˆ˜ ì €ì¥
    previous_height = len(driver.find_elements(By.CSS_SELECTOR, "#_pcmap_list_scroll_container > ul > li"))

    # ê¸°ë‹¤ë¦¬ëŠ” ì‹œê°„ ì„¤ì •
    wait = WebDriverWait(driver, 10)
    while True:
        try:
            # ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ ìš”ì†Œ ì°¾ê¸°
            element = driver.find_elements(By.CSS_SELECTOR, "#_pcmap_list_scroll_container > ul > li")[-1]
            
            # í•´ë‹¹ ìš”ì†Œê°€ ë³´ì¼ ë•Œê¹Œì§€ ìŠ¤í¬ë¡¤
            driver.execute_script("arguments[0].scrollIntoView(true);", element)
            
            # í˜ì´ì§€ê°€ ìŠ¤í¬ë¡¤ëœ í›„ ìƒˆë¡œìš´ ìš”ì†Œê°€ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "#_pcmap_list_scroll_container > ul > li:nth-child({})".format(previous_height + 1))))
            
            # ìƒˆë¡œìš´ ìš”ì†Œì˜ ìˆ˜ë¥¼ ê³„ì‚°
            new_height = len(driver.find_elements(By.CSS_SELECTOR, "#_pcmap_list_scroll_container > ul > li"))
            
            # ìƒˆë¡œìš´ ìš”ì†Œê°€ ë” ì´ìƒ ì¶”ê°€ë˜ì§€ ì•Šìœ¼ë©´ ì¢…ë£Œ
            if new_height == previous_height:
                break
            
            # ìŠ¤í¬ë¡¤ ì „ ìš”ì†Œ ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸
            previous_height = new_height
            
        except Exception as e:
            print(f"ìŠ¤í¬ë¡¤ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            break
    
    # í˜ì´ì§€ì˜ HTML ê°€ì ¸ì˜¤ê¸°
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    
    # ìŒì‹ì  ì´ë¦„, ë©”ë‰´, í‰ì , í”„ë¡œê·¸ë¨ ì¶œì—° ì •ë³´, ë¦¬ë·° ìˆ˜ ë“± í¬ë¡¤ë§
    restaurant_names = [restaurant_name.text for restaurant_name in soup.select(".place_bluelink")]
    restaurant_menus = [restaurant_menu.text for restaurant_menu in soup.select(".KCMnt")]
    
    # ìŒì‹ì  ë°ì´í„°ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    restaurant_data = {}
    
    # CSS ì…€ë ‰í„°ë¥¼ í•œ ë²ˆì— ì‚¬ìš©í•˜ì—¬ í•„ìš”í•œ ë°ì´í„°ë¥¼ ì¶”ì¶œ
    restaurant_containers = soup.select("#_pcmap_list_scroll_container ul li .MVx6e")

    for i, name in enumerate(restaurant_names):
        container = restaurant_containers[i]

        # ìŒì‹ì  ì •ë³´ë¥¼ ì¶”ì¶œ
        rate_element = container.select_one(".orXYY")
        program_element = container.select_one(".V1dzc")
        
        # ë¦¬ë·° ìš”ì†Œë¥¼ ì •í™•íˆ ì„ íƒí•˜ê¸° ìœ„í•´ 'ë¦¬ë·°' í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ spanì„ ê²€ìƒ‰
        review_element = None
        for span in container.select("span"):
            if "ë¦¬ë·°" in span.text:
                review_element = span
                break

        restaurant_data[name] = {}
        restaurant_data[name]["menu"] = restaurant_menus[i]

        # í‰ì  ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° Noneìœ¼ë¡œ ì„¤ì •
        if rate_element is None:
            restaurant_data[name]["rate"] = None
        else:
            try:
                restaurant_data[name]["rate"] = float(rate_element.text.lstrip("ë³„ì "))
            except ValueError:
                restaurant_data[name]["rate"] = None

        # í”„ë¡œê·¸ë¨ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° Noneìœ¼ë¡œ ì„¤ì •
        if program_element is None:
            restaurant_data[name]["program"] = None
        else:
            restaurant_data[name]["program"] = program_element.text.lstrip("TV")

        # ë¦¬ë·° ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° Noneìœ¼ë¡œ ì„¤ì •, ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¬ì‹œë„
        try:
            if review_element:
                review_text = review_element.text.lstrip("ë¦¬ë·° ").rstrip("+")
                restaurant_data[name]["review"] = int(review_text) if review_text.isdigit() else None
            else:
                restaurant_data[name]["review"] = None
        except ValueError:
            restaurant_data[name]["review"] = None

    driver.quit()

    # í˜„ì¬ ì‹œê°„ì— ë”°ë¼ íŒŒì¼ ì´ë¦„ ì„¤ì •
    current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_path = f"crawled_data_{current_time}.json"

    # JSON íŒŒì¼ë¡œ ì €ì¥
    json_data = json.dumps(restaurant_data, indent=2, ensure_ascii=False)
    with open(save_path, "w", encoding="utf-8") as f:
        f.write(json_data)
    
    return save_path


def crawl_school_meal():
    
    # JSONì— ì €ì¥í•  dictionary
    school_restaurant_data = {}

    options = webdriver.ChromeOptions()
    options.add_argument('--headless') 
    options.add_argument('--ignore-ssl-errors=yes')
    options.add_argument('--ignore-certificate-errors')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--no-sandbox')
    options.add_argument('--log-level=3')
    options.add_argument('--incognito')
    options.add_argument('--disable-images')
    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36 Edg/115.0.1901.200'
    options.add_argument(f'user-agent={user_agent}')
    
    # í¬ë¡¬ ì›¹ ë“œë¼ì´ë²„ ì‹¤í–‰
    driver = webdriver.Chrome(options=options)
    driver.get('https://chat.cau.ac.kr/v2/index.html')

    WebDriverWait(driver, 30).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, "#root > div > div > div.chat_container > div > div > div:nth-child(1) > div > div > div.card > div:nth-child(3) > div > div > ul:nth-child(1) > li:nth-child(2) > a"))
    )

    school_meal_tab = driver.find_element(By.CSS_SELECTOR, "#root > div > div > div.chat_container > div > div > div:nth-child(1) > div > div > div.card > div:nth-child(3) > div > div > ul:nth-child(1) > li:nth-child(2) > a")
    school_meal_tab.click()

    WebDriverWait(driver, 30).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, "#root > div > div > div.chat_container > div > div > div:nth-child(3) > div:nth-child(3) > div > div > div > div:nth-child(1) > div"))
    )

    time_now = datetime.now()

    if time_now.hour <= 10:
        time_num = 1
    elif time_now.hour > 10 or time_now.hour <= 15:
        time_num = 2
        n = 4
    else:
        time_num = 3
        n = 3
    
    meal_time = driver.find_element(By.CSS_SELECTOR, f"#root > div > div > div.chat_container > div > div > div:nth-child(3) > div:nth-child(3) > div > div > div > div:nth-child(1) > div > div > a:nth-child({time_num})")
    meal_time.click()

    if time_num==1:
        WebDriverWait(driver, 30).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "#root > div > div > div.chat_container > div > div > div:nth-child(5) > div.bubble_box > div > span"))
        )

        soup = BeautifulSoup(driver.page_source, 'html.parser')

        meal_data = soup.select_one("#root > div > div > div.chat_container > div > div > div:nth-child(5) > div.bubble_box > div > span").text

        # '-' ë’¤ì— ìˆëŠ” ë¶€ë¶„ì„ ì°¾ìŒ
        fixed_part = "-"
        menu_start_index = meal_data.find(fixed_part) + len(fixed_part)

        # ë©”ë‰´ ë¶€ë¶„ ìŠ¬ë¼ì´ì‹±
        menu_part = meal_data[menu_start_index:].strip()

        menu_list = list(menu_part.split(','))
        
        school_restaurant_data = {
            "ìƒí™œê´€ì‹ë‹¹(ë¸”ë£¨ë¯¸ë¥´308ê´€)": {
                "menu": {menu_item: {"type": menu_item} for menu_item in menu_list}
            }
        }

    else:
        WebDriverWait(driver, 30).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "#root > div > div > div.chat_container > div > div > div:nth-child(5) > div:nth-child(3) > div > div > div > div:nth-child(1) > div"))
        )

        soup = BeautifulSoup(driver.page_source, 'html.parser')

        restaurants = soup.select("#root > div > div > div.chat_container > div > div > div:nth-child(5) > div:nth-child(3) > div > div > div")

        restaurants_list = list()
        for i in range(n):
            restaurant = restaurants[0].select(f".bubble_box:nth-child({i+1})")
            restaurants_list.append(restaurant)
            
        for restaurant_unit in restaurants_list:
            meal_data = restaurant_unit[0].select_one(".bubble_box > .bubble_unit > span").get_text()
            menu_lines = meal_data.split('ğŸ”¹')  # 'ğŸ”¹'ë¡œ ê° ë©”ë‰´ë¥¼ êµ¬ë¶„

            if "ì°¸ìŠ¬ê¸°ì‹ë‹¹" in menu_lines[0]:
                menu_A = menu_lines[1].split('-')[1].split(',')  # ì²« ë²ˆì§¸ ë©”ë‰´
                menu_B = menu_lines[2].split('-')[1].split(',')  # ë‘ ë²ˆì§¸ ë©”ë‰´

                school_restaurant_data["ì°¸ìŠ¬ê¸°ì‹ë‹¹(310ê´€ B4ì¸µ)"] = {
                    "A": {"menu":{item.strip(): {"type": item.strip()} for item in menu_A}},
                    "B": {"menu":{item.strip(): {"type": item.strip()} for item in menu_B}}
                }
                continue
            
            restaurant_name = menu_lines[0].split(' ')[1]

            menu_list = list()
            for menu in menu_lines[1:]:
                menu = menu.split('-')[1].split(',')
                menu_list.extend(menu)
            
            school_restaurant_data[restaurant_name] = {
                "menu":{item:{'type': item} for item in menu_list}
            }
    
    
    driver.quit()

    # íŒŒì¼ ëª…ì— ì½”ë“œë¥¼ ì‹¤í–‰í•œ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜ì˜
    current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_path = f"school_meal_{current_time}.json"

    # í•™ì‹ ì •ë³´ dictionaryë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ JSONíŒŒì¼ì— ì €ì¥
    json_data = json.dumps(school_restaurant_data, indent=2, ensure_ascii=False)
    with open(save_path, 'w', encoding="utf-8") as f:
        f.write(json_data)

    return save_path


if __name__ == "__main__":
    # ìŒì‹ì  í¬ë¡¤ë§ ì˜ˆì‹œ
    radius = 15  # ë°˜ê²½ 15km
    print(f"Crawled restaurant data saved to: {crawl(radius)}")

    # í•™ì‹ í¬ë¡¤ë§ ì˜ˆì‹œ
    print(f"Crawled school meal data saved to: {crawl_school_meal()}")
